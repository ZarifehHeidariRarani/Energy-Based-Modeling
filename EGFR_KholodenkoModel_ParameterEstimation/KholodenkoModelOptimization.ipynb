{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook, we apply a parameter estimation method on Kholodenko's model of EGFR signalling pathway. This involves performing parameter estimation, then assessing the quality of the optimized model.\n",
    "\n",
    "The model that is taken from [Kholodenko et. al (1999)](https://www.sciencedirect.com/science/article/pii/S0021925819518804), and has already been implemented in the rule-based modeling using BioNetGen and also in the\n",
    "systems biology model specification format (SBML).\n",
    "\n",
    "The model in Step 4 recovers the Kholodenko's output, but the results of the Kholodenko's model do not fit the experimental data very well, as we can see in the following figure. As a result, in order to discover a set of optimized parameters, I employed a parameter estimation method for the model in Step 4. \n",
    "\n",
    "The set of optimized parameters seeks to provide outputs which best follow the experimental data in Kholodenko's paper. \n",
    "</ul>\n",
    "In this figure, you can see the Kholodenko's model output vs experimental data:\n",
    "\n",
    "\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "![Image1](ORIGINALKHOLO.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Specification, Import, and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import petab\n",
    "import pypesto\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.petab\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "import amici\n",
    "from pypesto.store import read_from_hdf5, save_to_hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter estimation problem has also already been formulated in [PEtab](https://github.com/PEtab-dev/PEtab) [3].\n",
    "The PEtab format is compatible with a variety of tools that are primarily developed within the systems biology community. Here, the [pyPESTO](https://github.com/ICB-DCM/pyPESTO) tool is for parameter estimation. \n",
    "\n",
    "The default simulation tool used by pyPESTO is [AMICI](https://github.com/AMICI-dev/AMICI).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_problem = petab.Problem.from_yaml(\n",
    "    \n",
    "   \"../EGFR/EGFR.yaml\"    #state the exact folder contains the yaml file\n",
    ")\n",
    "importer = pypesto.petab.PetabImporter(petab_problem)\n",
    "# import to pypesto\n",
    "problem = importer.create_problem()\n",
    "model = importer.create_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "A multi-start optimization is used here, to efficiently explore the parameter space for optima. The author' experience with the difficulty of optimizing this problem led her to use the [Fides](https://github.com/fides-dev/fides) optimizer.\n",
    "The choice of number of starts is problem-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer object which contains all information for doing the optimization\n",
    "options = {'maxiter':2000}\n",
    "optimizer = optimize.FidesOptimizer(options=options)\n",
    "engine = pypesto.engine.MultiProcessEngine()\n",
    "\n",
    "# do the optimization\n",
    "result = optimize.minimize(\n",
    "    problem=problem, optimizer=optimizer, n_starts=50, engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Assessment of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot here is the waterfall plot, which shows the likelihood function value of the estimated parameter values at the end of each optimization run (start). The runs are ordered by likelihood function value. Generally, a plateau of a few starts suggests a successful optimization with the good optima found. \n",
    "\n",
    "If the waterfall plot does not show a plateau at the minimum, the bounds can be adjusted (preferably to more realistic bounds), or the optimization can be run with a higher number of starts, or a different optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.waterfall(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "![Image1](Waterfall.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second plot is the parameters plot, which shows the estimated parameter values for each parameter at the end of each start. The vector of parameter values from a single start is indicated by connected dots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parameters(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "![Image1](Parameters.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conveniently visualize the model fit. This plots the petab visualization using optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.visualize.model_fit import visualize_optimized_model_fit\n",
    "pp1 = visualize_optimized_model_fit(petab_problem=petab_problem, result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</ul>\n",
    "<br>\n",
    "\n",
    "![Image1](Optimization.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of Maximum Likelihood Estimate\n",
    "\n",
    "Once optimization appears successful, the maximum likelihood estimate (MLE) can be assessed for parameter and prediction uncertainty.\n",
    "\n",
    "Parameter uncertainty can be assessed with MCMC sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Sampling\n",
    "\n",
    "MCMC sampling is a method of analysing the uncertainty of a parameter estimate. Here, the adaptive Metropolis-Hastings algorithm is used, with parallel tempering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle = result.optimize_result.list[0]['x'] # Maximum likelihood from optimization\n",
    "\n",
    "sampler = sample.AdaptiveParallelTemperingSampler(\n",
    "    internal_sampler=sample.AdaptiveMetropolisSampler(), n_chains=3\n",
    ")\n",
    "\n",
    "result = sample.sample(\n",
    "    problem,\n",
    "    n_samples=10000,\n",
    "    sampler=sampler,\n",
    "    x0 = mle\n",
    ")\n",
    "elapsed_time = result.sample_result.time\n",
    "print(f\"Elapsed time: {round(elapsed_time,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the result, we can plot e.g. kernel density estimates or histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    pypesto.visualize.sampling_1d_marginals(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain:{i_chain}\", size = (40,32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The samples of the first chain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image1](MCMCchains_0.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The samples of the second chain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image1](MCMCchains_1.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The samples of the third chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image1](MCMCchains_2.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, also the log posterior trace can be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    plt.figure()\n",
    "    plt.plot(np.log10(result.sample_result.trace_neglogpost[i_chain]),'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log posterior of the first chain\n",
    "x and y-axis show the iterations and log posterior of function values, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image1](logfvaltrace_0.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log posterior of the second chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image1](logfvaltrace_1.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The log posterior of the third chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image1](logfvaltrace_2.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter trajectories can alse be visualized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "     visualize.sampling_parameter_traces(\n",
    "        result, i_chain=i_chain, size = (40,32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter trajectories of the first chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](parametertrace_0.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter trajectories of the second chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](parametertrace_1.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parameter trajectories of the third chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](parametertrace_2.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot approximate confidence intervals based on MCMC chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [99, 95, 90]\n",
    "ax = visualize.sampling_parameter_cis(result, alpha=alpha, size=(25, 30), step =0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](CIS.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC sampling diagnostics\n",
    "\n",
    "## Prediction Uncertainties Observables\n",
    "\n",
    "To assess prediction uncertainty, the MCMC samples are simulated as an ensemble, and state and observable trajectories for each sample are saved. Percentiles are then computed based on the ensemble predictions.\n",
    "In this part we illustrate how to assess the quality of the MCMC samples. \n",
    "\n",
    "Predictions can be performed by creating a parameter ensemble from the sample, then applying a predictor to the ensemble. The predictor requires a simulation tool. Here, AMICI is used. First, the predictor is setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.C import AMICI_STATUS, AMICI_T, AMICI_X, AMICI_Y\n",
    "from pypesto.predict import AmiciPredictor\n",
    "from pypesto.C import EnsembleType\n",
    "import numpy as np\n",
    "from pypesto.ensemble import Ensemble\n",
    "# such that the output is compatible with the next steps.\n",
    "def post_processor(amici_outputs, output_type, output_ids):\n",
    "    outputs = [\n",
    "        amici_output[output_type]\n",
    "        if amici_output[AMICI_STATUS] == 0\n",
    "        else np.full((len(amici_output[AMICI_T]), len(output_ids)), np.nan)\n",
    "        for amici_output in amici_outputs\n",
    "    ]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# Setup post-processors for both states and observables.\n",
    "from functools import partial\n",
    "\n",
    "amici_objective = result.problem.objective\n",
    "state_ids = amici_objective.amici_model.getStateIds()\n",
    "observable_ids = amici_objective.amici_model.getObservableIds()\n",
    "post_processor_x = partial(\n",
    "    post_processor,\n",
    "    output_type=AMICI_X,\n",
    "    output_ids=state_ids,\n",
    ")\n",
    "post_processor_y = partial(\n",
    "    post_processor,\n",
    "    output_type=AMICI_Y,\n",
    "    output_ids=observable_ids,\n",
    ")\n",
    "\n",
    "# Create pyPESTO predictors for states and observables\n",
    "predictor_x = AmiciPredictor(\n",
    "    amici_objective,\n",
    "    post_processor=post_processor_x,\n",
    "    output_ids=state_ids,\n",
    ")\n",
    "predictor_y = AmiciPredictor(\n",
    "    amici_objective,\n",
    "    post_processor=post_processor_y,\n",
    "    output_ids=observable_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the ensemble is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.C import EnsembleType\n",
    "from pypesto.ensemble import Ensemble\n",
    "\n",
    "# corresponds to only the estimated parameters\n",
    "x_names = result.problem.get_reduced_vector(result.problem.x_names)\n",
    "\n",
    "# Create the ensemble with the MCMC chain from parallel tempering with the real temperature.\n",
    "ensemble = Ensemble.from_sample(\n",
    "    result,\n",
    "    x_names=x_names,\n",
    "    ensemble_type=EnsembleType.sample,\n",
    "    lower_bound=result.problem.lb,\n",
    "    upper_bound=result.problem.ub,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor is then applied to the ensemble to generate predictions in a limited time points in which we have experimental data, then plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.engine import MultiThreadEngine\n",
    "engine = MultiThreadEngine()\n",
    "\n",
    "ensemble_prediction = ensemble.predict(\n",
    "    predictor_x, prediction_id=AMICI_X, engine=engine\n",
    ")\n",
    "# Create the ensemble with the MCMC chain from parallel tempering with the real temperature.\n",
    "ensemble = Ensemble.from_sample(\n",
    "    result,\n",
    "    x_names=x_names,\n",
    "    ensemble_type=EnsembleType.sample,\n",
    "    lower_bound=result.problem.lb,\n",
    "    upper_bound=result.problem.ub,\n",
    ")\n",
    "\n",
    "ensemble_prediction = ensemble.predict(\n",
    "    predictor_y, prediction_id=AMICI_Y, engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting based on each experimental condition\n",
    "## Condition 0 is initial concentration for EGF = 0.2 nM\n",
    "## Condition 1 is initial concentration for EGF = 2 nM\n",
    "## Condition 2 is initial concentration for EGF = 20 nM\n",
    "\n",
    "from pypesto.C import CONDITION, OUTPUT\n",
    "credibility_interval_levels = [90, 95, 99]\n",
    "ax = visualize.sampling_prediction_trajectories(\n",
    "    ensemble_prediction,\n",
    "    levels=credibility_interval_levels,\n",
    "    size=(15, 9),\n",
    "    axis_label_padding=60,\n",
    "    groupby=CONDITION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black lines in each plot shows the observables which obtained using maximum likelihood, and the color shadows show the observables which obtained applying the MCMC samples as an ensemble to show the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](observable_condition.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting based on each observable\n",
    "ax = visualize.sampling_prediction_trajectories(\n",
    "    ensemble_prediction,\n",
    "    levels=credibility_interval_levels,\n",
    "    size=(15, 9),\n",
    "    axis_label_padding=60,\n",
    "    groupby=OUTPUT,\n",
    "    reverse_opacities=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](observable_output.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom timepoints can also be specified, either for each condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom objective with new output timepoints.\n",
    "timepoints = [np.linspace(0, 120, 121), np.linspace(0, 120, 121), np.linspace(0, 120, 121)]\n",
    "amici_objective_custom = amici_objective.set_custom_timepoints(\n",
    "    timepoints=timepoints\n",
    ")\n",
    "\n",
    "# Create an observable predictor with the custom objective.\n",
    "predictor_y_custom = AmiciPredictor(\n",
    "    amici_objective_custom,\n",
    "    post_processor=post_processor_y,\n",
    "    output_ids=observable_ids,\n",
    ")\n",
    "\n",
    "# Predict then plot.\n",
    "ensemble_prediction = ensemble.predict(\n",
    "    predictor_y_custom, prediction_id=AMICI_Y, engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.sampling_prediction_trajectories(\n",
    "    ensemble_prediction,\n",
    "    levels=credibility_interval_levels,\n",
    "    groupby=CONDITION,\n",
    "    size=(15, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](simulated_condition.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.sampling_prediction_trajectories(\n",
    "    ensemble_prediction,\n",
    "    levels=credibility_interval_levels,\n",
    "    groupby=OUTPUT,\n",
    "    size=(15, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](simulated_output.png)\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
