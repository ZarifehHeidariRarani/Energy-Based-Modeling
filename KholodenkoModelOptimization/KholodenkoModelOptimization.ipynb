{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook, we apply a parameter estimation method on Kholodenko's model of EGFR signalling pathway. This involves performing parameter estimation, then assessing the quality of the optimized model.\n",
    "\n",
    "The model that is taken from [Kholodenko et. al (1999)](https://www.sciencedirect.com/science/article/pii/S0021925819518804), and has already been implemented in the rule-based modeling using BioNetGen and also in the\n",
    "systems biology model specification format (SBML).\n",
    "\n",
    "The model in Step 4 recovers the Kholodenko's output, but the results of the Kholodenko's model do not fit the experimental data very well, as we can see in the following figure. As a result, in order to discover a set of optimized parameters, I employed a parameter estimation method for the model in Step 4. \n",
    "\n",
    "The set of optimized parameters seeks to provide outputs which best follow the experimental data in Kholodenko's paper. \n",
    "</ul>\n",
    "In this figure, you can see the Kholodenko's model output vs experimental data:\n",
    "\n",
    "\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "![KholodenkoModel.png](KholodenkoModel.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Specification, Import, and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import petab\n",
    "import pypesto\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.petab\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "import amici\n",
    "from pypesto.store import read_from_hdf5, save_to_hdf5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter estimation problem has also already been formulated in [PEtab](https://github.com/PEtab-dev/PEtab) [3].\n",
    "The PEtab format is compatible with a variety of tools that are primarily developed within the systems biology community. Here, the [pyPESTO](https://github.com/ICB-DCM/pyPESTO) tool is for parameter estimation. \n",
    "\n",
    "The default simulation tool used by pyPESTO is [AMICI](https://github.com/AMICI-dev/AMICI).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_problem = petab.Problem.from_yaml(\n",
    "    \n",
    "   \"../EGFR/EGFR.yaml\"    #state the exact folder contains the yaml file\n",
    ")\n",
    "importer = pypesto.petab.PetabImporter(petab_problem)\n",
    "# import to pypesto\n",
    "problem = importer.create_problem()\n",
    "model = importer.create_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "A multi-start optimization is used here, to efficiently explore the parameter space for optima. The author' experience with the difficulty of optimizing this problem led her to use the [Fides](https://github.com/fides-dev/fides) optimizer.\n",
    "The choice of number of starts is problem-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer object which contains all information for doing the optimization\n",
    "options = {'maxiter':2000}\n",
    "optimizer = optimize.FidesOptimizer(options=options)\n",
    "engine = pypesto.engine.MultiProcessEngine()\n",
    "\n",
    "# do the optimization\n",
    "result = optimize.minimize(\n",
    "    problem=problem, optimizer=optimizer, n_starts=100, engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Assessment of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot here is the waterfall plot, which shows the likelihood function value of the estimated parameter values at the end of each optimization run (start). The runs are ordered by likelihood function value. Generally, a plateau of a few starts suggests a successful optimization with the good global optima found. Other colors are used here to indicate plateaus showing different local optimums.\n",
    "\n",
    "If the waterfall plot does not show a plateau at the minimum, the bounds can be adjusted (preferably to more realistic bounds), or the optimization can be run with a higher number of starts, or a different optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.waterfall(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "![waterfallplot](waterfallplot.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second plot is the parameters plot, which shows the estimated parameter values for each parameter at the end of each start. The vector of parameter values from a single start is indicated by connected dots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parameters(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "![Parametersplot](Parametersplot.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conveniently visualize the model fit. This plots the petab visualization using optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.visualize.model_fit import visualize_optimized_model_fit\n",
    "pp1 = visualize_optimized_model_fit(petab_problem=petab_problem, result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</ul>\n",
    "<br>\n",
    "\n",
    "![Optimizationplot](Optimizationplot.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative or positive cooperativity of ShcP in the model:\n",
    "\n",
    "Based on the estimated parameters, it seems that the affinity of Shc for binding to EGFR intensively decreases after phosphorylation.\n",
    "\n",
    "### v13: EGFR + Shc\n",
    "```\n",
    "K13 = 1.7e-4\n",
    "```\n",
    "### v15: EGFRShcP Breaking apart\n",
    "```\n",
    "K15 = 3.3e-11\n",
    "```\n",
    "### Cooperativity of ShcP in the original Kholodenko model\n",
    "For original Kholodenko model we have:\n",
    "```\n",
    "K13 = 0.15\n",
    "```\n",
    "```\n",
    "K15 = 0.003\n",
    "```\n",
    "Based on these values, in the original Kholodenko’s model, the affinity of Shc for binding to EGFR decreases after phosphorylation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of Maximum Likelihood Estimate\n",
    "\n",
    "Once optimization appears successful, the maximum likelihood estimate (MLE) can be assessed for parameter and prediction uncertainty.\n",
    "\n",
    "Parameter uncertainty can be assessed with MCMC sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Sampling\n",
    "\n",
    "MCMC sampling is a method of analysing the uncertainty of a parameter estimate. Here, the adaptive Metropolis-Hastings algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle = result.optimize_result.list[0]['x'] # Maximum likelihood from optimization\n",
    "\n",
    "sampler = sample.MetropolisSampler({'std': 0.00005})\n",
    "\n",
    "result = sample.sample(\n",
    "    problem,\n",
    "    n_samples = 2.5e6,\n",
    "    sampler = sampler,\n",
    "    x0 = mle\n",
    ")\n",
    "elapsed_time = result.sample_result.time\n",
    "print(f\"Elapsed time: {round(elapsed_time,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we determine the acceptance rate of the MCMC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acceptance(samp_result):\n",
    "    params = samp_result['trace_x'][0]\n",
    "    accept = [0 if (params[i, :] == params[i-1, :]).all() else 1 \n",
    "              for i in range(1, params.shape[0])]\n",
    "    num_accept = np.sum(accept)\n",
    "    rate = num_accept / (params.shape[0] - 1)\n",
    "    return rate\n",
    "\n",
    "accept_rate = calc_acceptance(result.sample_result)\n",
    "print(\"The acceptance rate of MCMC is:  %.4f%%\"%(accept_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acceptance rate of MCMC is:  98.9083%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acceptance rate is high and it's beacause the std value for sampling is very small (0.00005)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every Markov chain needs a certain amount of iterations to reach the stationary distribution. Sometimes the chain quickly get to the regions with relative high density, for some situations, especially for multiparameter problems, it usually takes hundreds or thousands of iterations to get there. Iterations obtained before a Markov chain reaches the stationary distribution are called burn-in and can be determined using Geweke test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.geweke_test(result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geweke burn-in index: 1375000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result\n",
    "#### Log posterior \n",
    "x and y-axis show the iterations and log posterior of function values, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.sampling_fval_traces(result, size = (13,4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fvaltraceplot](fvaltraceplot.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-posterior chain should be smoothly varying around the maximum. We can say it has been obtained in this sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter trajectories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.sampling_parameter_traces(\n",
    "    result, use_problem_bounds=True, size=(30,24), stepsize = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ParameterTraces](ParameterTraces.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two of the parameters we show the MLE and parameter traces simultaneously, which shows the samples are around the MLE, but again the variations of parameter traces are very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ParameterTraces_1_hline](ParameterTraces_1_hline.png)\n",
    "<br><br>\n",
    "\n",
    "![ParameterTraces_2_hline](ParameterTraces_2_hline.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot e.g. kernel density estimates or histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypesto.visualize.sampling_1d_marginals(\n",
    "        result, size = (30,24)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCMCchainsplot](MCMCchainsplot.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these histograms, the variations are very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Tempering MCMC\n",
    "\n",
    "We also use the parallel tempering MCMC sampling for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = sample.ParallelTemperingSampler(\n",
    "    internal_sampler=sample.MetropolisSampler(),  n_chains=5\n",
    ")\n",
    "\n",
    "result = sample.sample(\n",
    "    problem = problem, \n",
    "    n_samples = 5e5,\n",
    "    sampler = sampler,\n",
    "    x0 = mle\n",
    ")\n",
    "\n",
    "elapsed_time = result.sample_result.time\n",
    "print(f\"Elapsed time: {round(elapsed_time,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acceptance(samp_result):\n",
    "    params = samp_result['trace_x'][0]\n",
    "    accept = [0 if (params[i, :] == params[i-1, :]).all() else 1 \n",
    "              for i in range(1, params.shape[0])]\n",
    "    num_accept = np.sum(accept)\n",
    "    rate = num_accept / (params.shape[0] - 1)\n",
    "    return rate\n",
    "\n",
    "accept_rate = calc_acceptance(result.sample_result)\n",
    "print(\"The acceptance rate of MCMC is:  %.4f%%\"%(accept_rate*100))\n",
    "\n",
    "sample.geweke_test(result= result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acceptance rate of MCMC is 23.3938%\n",
    "\n",
    "Geweke burn-in index: 325000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we’re using the Metropolis algorithm, we want to monitor the acceptance rate and make sure it is within optimal range. If we accept almost every time, that tells us that each time the chain only jumps a very small step (so that the acceptance ratio is close to 1 every time), which will make the algorithm slow in converging to the stationary distribution.\n",
    "\n",
    "On the other hand, if the acceptance rate is very low, then that says that the chain got stuck to just a few locations and it takes hundreds of iterations for it to make one jump. For the Metropolis algorithm, an optimal acceptance rate would be something between 10% to 60%. \n",
    "\n",
    "For our model, the acceptance rate is within the optimal range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_fval_traces(result,  i_chain=i_chain, size = (13,4), stepsize= 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fvaltrace_chain0](fvaltrace_chain0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fvaltrace_chain1](fvaltrace_chain1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fvaltrace_chain2](fvaltrace_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fvaltrace_chain3](fvaltrace_chain3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fvaltrace_chain4](fvaltrace_chain4.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the trace plots better and also make it possible to compare the traces in different chains. We have shown several parameter traces here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 30\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_parameter_traces(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\", par_indices = [n_par], stepsize=100\n",
    "    )\n",
    "    plt.axhline(y = mle[n_par], color='r')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pram_Trace_300](Pram_Trace_300.png)\n",
    "![Pram_Trace_301](Pram_Trace_301.png)\n",
    "![Pram_Trace_302](Pram_Trace_302.png)\n",
    "![Pram_Trace_303](Pram_Trace_303.png)\n",
    "![Pram_Trace_304](Pram_Trace_304.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 24\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_parameter_traces(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\", par_indices = [n_par], stepsize=100\n",
    "    )\n",
    "    plt.axhline(y = mle[n_par], color='r')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pram_Trace_240](Pram_Trace_240.png)\n",
    "![Pram_Trace_241](Pram_Trace_241.png)\n",
    "![Pram_Trace_242](Pram_Trace_242.png)\n",
    "![Pram_Trace_243](Pram_Trace_243.png)\n",
    "![Pram_Trace_244](Pram_Trace_244.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 29\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_parameter_traces(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\", par_indices = [n_par], stepsize=100\n",
    "    )\n",
    "    plt.axhline(y = mle[n_par], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pram_Trace_290](Pram_Trace_290.png)\n",
    "![Pram_Trace_291](Pram_Trace_291.png)\n",
    "![Pram_Trace_292](Pram_Trace_292.png)\n",
    "![Pram_Trace_293](Pram_Trace_293.png)\n",
    "![Pram_Trace_294](Pram_Trace_294.png)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample traces are varied around the MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of samples \n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_1d_marginals(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 1 \n",
    "![MCMCchains_PT:0](MCMCchains_PT:0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 2 \n",
    "![MCMCchains_PT:1](MCMCchains_PT:1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 3 \n",
    "![MCMCchains_PT:2](MCMCchains_PT:2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 4 \n",
    "![MCMCchains_PT:3](MCMCchains_PT:3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 5\n",
    "![MCMCchains_PT:4](MCMCchains_PT:4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For having a better comparison, we concentrate on two parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 30\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_1d_marginals(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\", par_indices= [n_par]\n",
    "    )\n",
    "    plt.axvline(x = mle[n_par], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCMC_V160](MCMC_V160.png)\n",
    "![MCMC_V161](MCMC_V161.png)\n",
    "![MCMC_V16f2](MCMC_V162.png)\n",
    "![MCMC_V16f3](MCMC_V163.png)\n",
    "![MCMC_V16f4](MCMC_V164.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 4 last chains are almost the same. The first chain is a bit different between these chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 24\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_1d_marginals(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\", par_indices= [n_par]\n",
    "    )\n",
    "    plt.axvline(x = mle[n_par], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCMC_K13f0](MCMC_K13f0.png)\n",
    "![MCMC_K13f1](MCMC_K13f1.png)\n",
    "![MCMC_K13f2](MCMC_K13f2.png)\n",
    "![MCMC_K13f3](MCMC_K13f3.png)\n",
    "![MCMC_K13f4](MCMC_K13f4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 4\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_1d_marginals(\n",
    "        result, i_chain=i_chain, suptitle=f\"Chain: {i_chain}\", par_indices= [n_par]\n",
    "    )\n",
    "    plt.axvline(x = mle[n_par], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCMC_K3f0](MCMC_K3f0.png)\n",
    "![MCMC_K3f1](MCMC_K3f1.png)\n",
    "![MCMC_K3f2](MCMC_K3f2.png)\n",
    "![MCMC_K3f3](MCMC_K3f3.png)\n",
    "![MCMC_K3f4](MCMC_K3f4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gelman-Rubin Convergence Diagnostic\n",
    "\n",
    "Gelman and Rubin diagnostics is introduce in Gelman and Rubin (1992) to compare several chains. This approach is based on the analysis of variance. Approximate convergence is diagnosed when the variance between the different chain, B is no larger than the variance within each individual chain, W.\n",
    "\n",
    "Then, potential scale reduction factor (PSRF) is calculated for each of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "PSRF = \n",
    "[1.14082463 1.23114944 1.12906588 1.01141539 1.04598493 1.99077817\n",
    " 1.6706821  1.8148313  1.41068425 1.12990836 1.04368458 1.16037462\n",
    " 1.61973931 1.32567647 1.01141244 1.33286995 1.36766626 1.12544081\n",
    " 1.07194149 1.00064802 1.21010824 1.84223955 1.09701744 1.4204779\n",
    " 1.03900114 1.38375614 1.3860118  1.24321072 1.20868943 1.14649828\n",
    " 1.00108959 1.19596478 1.24719141 1.25615038 1.00647217 1.11599609\n",
    " 1.0018266  1.26464576 1.00826417 1.07113752 1.11365357 1.10511415\n",
    " 1.05842486 1.42407651 1.0937442  1.5660906  1.18939625 1.02829364\n",
    " 1.59172539 1.54878106]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
