{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook, we apply a parameter estimation method on Kholodenko's model of EGFR signalling pathway. This involves performing parameter estimation, then assessing the quality of the optimized model.\n",
    "\n",
    "The model that is taken from [Kholodenko et. al (1999)](https://www.sciencedirect.com/science/article/pii/S0021925819518804), and has already been implemented in the rule-based modeling using BioNetGen and also in the\n",
    "systems biology model specification format (SBML).\n",
    "\n",
    "The model in Step 4 recovers the Kholodenko's output, but the results of the Kholodenko's model do not fit the experimental data very well, as we can see in the following figure. Moreover, there are some inconsistancies in the parameters which are involved in the thermodynamic restrictions along cyclic pathways in the Kholodenko's model. As a result, in order to discover a set of optimized parameters which not only provides an appropriate fit to the experimental data but also satisfies the detailed balance constraints, I employed a parameter estimation method for the model in Step 4. \n",
    "\n",
    "The set of optimized parameters seeks to provide outputs which best follow the experimental data in Kholodenko's paper. \n",
    "</ul>\n",
    "In this figure, you can see the Kholodenko's model output vs experimental data:\n",
    "\n",
    "\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "![KholodenkoModel.png](KholodenkoModel.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Specification, Import, and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import petab\n",
    "import pypesto\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.petab\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "import amici\n",
    "from pypesto.store import read_from_hdf5, save_to_hdf5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter estimation problem has also already been formulated in [PEtab](https://github.com/PEtab-dev/PEtab).\n",
    "The PEtab format is compatible with a variety of tools that are primarily developed within the systems biology community. Here, the [pyPESTO](https://github.com/ICB-DCM/pyPESTO) tool is for parameter estimation. \n",
    "\n",
    "The default simulation tool used by pyPESTO is [AMICI](https://github.com/AMICI-dev/AMICI).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_problem = petab.Problem.from_yaml(\n",
    "    \n",
    "   \"../EGFR/EGFR.yaml\"    #state the exact folder contains the yaml file\n",
    ")\n",
    "importer = pypesto.petab.PetabImporter(petab_problem)\n",
    "# import to pypesto\n",
    "problem = importer.create_problem()\n",
    "model = importer.create_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "A multi-start optimization is used here, to efficiently explore the parameter space for optima. The author's experience with the difficulty of optimizing this problem led her to use the [Fides](https://github.com/fides-dev/fides) optimizer.\n",
    "The choice of number of starts is problem-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer object which contains all information for doing the optimization\n",
    "options = {'maxiter':2000}\n",
    "optimizer = optimize.FidesOptimizer(options=options)\n",
    "engine = pypesto.engine.MultiProcessEngine()\n",
    "\n",
    "# do the optimization\n",
    "result = optimize.minimize(\n",
    "    problem=problem, optimizer=optimizer, n_starts=200, engine=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Assessment of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot here is the waterfall plot, which shows the likelihood function value of the estimated parameter values at the end of each optimization run (start). The runs are ordered by likelihood function value. Generally, a plateau of a few starts suggests a successful optimization with the good global optima found. Other colors are used here to indicate plateaus showing different local optimums.\n",
    "\n",
    "If the waterfall plot does not show a plateau at the minimum, the bounds can be adjusted (preferably to more realistic bounds), or the optimization can be run with a higher number of starts, or a different optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.waterfall(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![waterfall](Waterfall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure allows us to compare three sets of the model parameters:\n",
    "\n",
    "1- The values in the original Kholodenko's paper: Green dots\n",
    "\n",
    "2- The estimated values without detailed balance constraints: Red dots\n",
    "\n",
    "3- The estimated values with detailed balance constraints: Black dots\n",
    "\n",
    "More comparisons for these three methods have been provided in a file, [here](https://github.com/ZarifehHeidariRarani/Energy-Based-Modeling/blob/main/KholodenkoModel_DetailedBalance/Comparing_based_on_DetailedBalanceConstraints.docx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parameters_withoutIC.png](Parameters_withoutIC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conveniently visualize the model fit. This plots the petab visualization using optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.visualize.model_fit import visualize_optimized_model_fit\n",
    "pp1 = visualize_optimized_model_fit(petab_problem=petab_problem, result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Optimization](Optimization.png)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Cooperativity of ShcP in the original Kholodenko model\n",
    "For original Kholodenko model we have:\n",
    "\n",
    "#### v13: Unphosphorylated Shc + EGFR\n",
    "```\n",
    "K13 = 0.15\n",
    "```\n",
    "#### v15: Phosphorylated Shc + EGFR\n",
    "```\n",
    "K15 = 0.003\n",
    "```\n",
    "### Negative or positive cooperativity of ShcP in the model:\n",
    "\n",
    "#### v13: Unphosphorylated Shc + EGFR\n",
    "```\n",
    "K13 = 7.1e-4\n",
    "```\n",
    "#### v15: Phosphorylated Shc + EGFR\n",
    "```\n",
    "K15 = 1.48e-7\n",
    "```\n",
    "Based on the estimated parameters, it seems that for both sets of parameter values the affinity of Shc for binding to EGFR intensively decreases after phosphorylation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of Maximum Likelihood Estimate\n",
    "\n",
    "Once optimization appears successful, the maximum likelihood estimate (MLE) can be assessed for parameter and prediction uncertainty.\n",
    "\n",
    "Parameter uncertainty can be assessed with MCMC sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Sampling\n",
    "\n",
    "Markov chain Monte Carlo (MCMC) sampling is a method of analysing the uncertainty of a parameter estimate. Here,  Parallel Tempering MCMC and adaptive Metropolis algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle = result.optimize_result.list[0]['x'] # Maximum likelihood from optimization\n",
    "\n",
    "sampler = sample.ParallelTemperingSampler(\n",
    "   internal_sampler=sample.AdaptiveMetropolisSampler(), n_chains = 5\n",
    ")\n",
    "result = sample.sample(\n",
    "    problem = problem, \n",
    "    n_samples = 2e6,\n",
    "    sampler = sampler,\n",
    "    x0 = mle\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we determine the acceptance rate of the MCMC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acceptance(samp_result):\n",
    "    params = samp_result['trace_x'][0]\n",
    "    accept = [0 if (params[i, :] == params[i-1, :]).all() else 1 \n",
    "              for i in range(1, params.shape[0])]\n",
    "    num_accept = np.sum(accept)\n",
    "    rate = num_accept / (params.shape[0] - 1)\n",
    "    return rate\n",
    "\n",
    "accept_rate = calc_acceptance(result.sample_result)\n",
    "print(\"The acceptance rate of MCMC is:  %.2f%%\"%(accept_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acceptance rate of MCMC is:  29.59%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to monitor the acceptance rate and make sure it is within optimal range. If we accept almost every time, that tells us that each time the chain only jumps a very small step (so that the acceptance ratio is close to 1 every time), which will make the algorithm slow in converging to the stationary distribution.\n",
    "\n",
    "On the other hand, if the acceptance rate is very low, then that says that the chain got stuck to just a few locations and it takes hundreds of iterations for it to make one jump. For the Metropolis algorithm, an optimal acceptance rate would be something between 10% to 60%. \n",
    "\n",
    "For our model, the acceptance rate is within the optimal range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geweke Test\n",
    "\n",
    "Every Markov chain needs a certain amount of iterations to reach the stationary distribution. Sometimes the chain quickly get to the regions with relative high density, for some situations, especially for multiparameter problems, it usually takes hundreds or thousands of iterations to get there. Iterations obtained before a Markov chain reaches the stationary distribution are called burn-in and can be determined using Geweke test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.geweke_test(result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geweke burn-in index: 800000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result\n",
    "#### Log posterior \n",
    "x and y-axis show the iterations and log posterior of function values, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_fval_traces(result,  i_chain=i_chain, stepsize= 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 1\n",
    "\n",
    "![fval0](fval0.png)\n",
    "\n",
    "### Chain 2\n",
    "\n",
    "![fval1](fval1.png)\n",
    "\n",
    "### Chain 3\n",
    "\n",
    "![fval2](fval2.png)\n",
    "\n",
    "### Chain 4\n",
    "\n",
    "![fval3](fval3.png)\n",
    "\n",
    "### Chain 5\n",
    "\n",
    "![fval4](fval4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-posterior chain should be smoothly varying around the maximum. We can say it has been obtained in this sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter trajectories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par = 30\n",
    "for i_chain in range(len(result.sample_result.betas)):\n",
    "    visualize.sampling_parameter_traces(\n",
    "        result, i_chain=i_chain, par_indices = [4, 7, 8, 10], stepsize=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 1\n",
    "\n",
    "![ParamTrace0](ParamTrace0.png)\n",
    "\n",
    "### Chain 2\n",
    "\n",
    "![ParamTrace1](ParamTrace1.png)\n",
    "\n",
    "### Chain 3\n",
    "\n",
    "![ParamTrace2](ParamTrace2.png)\n",
    "\n",
    "### Chain 4\n",
    "\n",
    "![ParamTrace3](ParamTrace3.png)\n",
    "\n",
    "### Chain 5\n",
    "\n",
    "![ParamTrace4](ParamTrace4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can plot e.g. kernel density estimates or histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 1\n",
    "\n",
    "![MCMC0](MCMC0.png)\n",
    "\n",
    "### Chain 2\n",
    "\n",
    "![MCMC1](MCMC1.png)\n",
    "\n",
    "### Chain 3\n",
    "\n",
    "![MCMC2](MCMC2.png)\n",
    "\n",
    "### Chain 4\n",
    "\n",
    "![MCMC3](MCMC3.png)\n",
    "\n",
    "### Chain 5\n",
    "\n",
    "![MCMC4](MCMC4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For having a better view, histograms for several parameters are shown:\n",
    "\n",
    "### Chain 1\n",
    "\n",
    "![MCMC0_4](MCMC0_4.png)\n",
    "\n",
    "### Chain 2\n",
    "\n",
    "![MCMC1_4](MCMC1_4.png)\n",
    "\n",
    "### Chain 3\n",
    "\n",
    "![MCMC2_4](MCMC2_4.png)\n",
    "\n",
    "### Chain 4\n",
    "\n",
    "![MCMC3_4](MCMC3_4.png)\n",
    "\n",
    "### Chain 5\n",
    "\n",
    "![MCMC4_4](MCMC4_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gelman-Rubin Convergence Diagnostic\n",
    "\n",
    "Gelman and Rubin diagnostics is introduce in Gelman and Rubin (1992) to compare several chains. This approach is based on the analysis of variance. Approximate convergence is diagnosed when the variance between the different chain, is no larger than the variance within each individual chain.\n",
    "\n",
    "Then, potential scale reduction factor (PSRF) is calculated for each of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "PSRF = \n",
    "[1.00372036 1.00023034 1.0070337  1.00435328 1.00109211 1.00004674\n",
    " 1.00006971 1.00257258 1.00719548 1.00490399 1.00326198 1.00265316\n",
    " 1.00259543 1.01882634 1.00010566 1.00099842 1.00043986 1.00371582\n",
    " 1.00126627 1.00000426 1.00382374 1.00297572 1.00459077 1.00073319\n",
    " 1.00094755 1.00034744 1.00265541 1.00228857 1.00246688 1.00025032\n",
    " 1.00127031 1.00000288 1.00026312 1.00000407 1.00003315 1.0020304\n",
    " 1.00140989 1.00133685 1.00035036 1.00123513 1.00015638 1.00314101\n",
    " 1.00014624 1.00864126 1.16647382]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values of the matrix elements is close to 1 (smaller than 1.2), the theory claims that they should all eventually converge to the stationary distribution. The Gelman-Rubin statistic is a ratio, and hence unit free, making it a simple summary for any MCMC sampler. Therefore, it can be a useful tool for monitoring a chain before any specific decisions about what kinds of inferences will be made from the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd63fb3fc8983e44cd81d62c149e2bea465ce3bff353a0abcb5154557c593fd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
